{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(content=\"User's name is Angelo.\"),\n",
       " Memory(content='User likes to fly.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model_with_structure = model.with_structured_output(MemoryCollection)\n",
    "\n",
    "memory_collection = model_with_structure.invoke([HumanMessage(\"My name is Angelo. I like to fly.\")])\n",
    "memory_collection.memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"User's name is Angelo.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_collection.memories[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[0].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[1].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': {'content': \"User's name is Angelo.\"}, 'key': '64a862c4-ac93-4a95-a840-7ab6925a3727', 'namespace': ['1', 'memories'], 'created_at': '2025-01-01T22:24:55.938636+00:00', 'updated_at': '2025-01-01T22:24:55.938638+00:00', 'score': None}\n",
      "{'value': {'content': 'User likes to fly.'}, 'key': '9558e44b-67ee-4bb2-b5c1-c3daa7a178a7', 'namespace': ['1', 'memories'], 'created_at': '2025-01-01T22:24:55.938743+00:00', 'updated_at': '2025-01-01T22:24:55.938744+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating collection schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Angelo\"),\n",
    "                AIMessage(content=\"Nice to meet you Angelo\"),\n",
    "                HumanMessage(content=\"This morning I had a nice meal. I ate Shakshuka.\")]\n",
    "\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_ACKUajbkqNzz4laSE0Q3ddai)\n",
      " Call ID: call_ACKUajbkqNzz4laSE0Q3ddai\n",
      "  Args:\n",
      "    content: Angelo had a nice meal this morning and ate Shakshuka.\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_ACKUajbkqNzz4laSE0Q3ddai'}\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Angelo had a nice meal this morning and ate Shakshuka.'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_conversation = [AIMessage(content=\"That's great, what did you do after?\"),\n",
    "                        HumanMessage(content=\"I flew to the moon and made a Tulpa.\"),\n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about dogs chasing their tails\")]\n",
    "\n",
    "system_msg = \"\"\"Update existing memories and acreate new ones based on the following conversation:\"\"\"\n",
    "\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_mF1o26UtKwTtgKAFra7PAqQt)\n",
      " Call ID: call_mF1o26UtKwTtgKAFra7PAqQt\n",
      "  Args:\n",
      "    content: Angelo had a nice meal this morning and ate Shakshuka. After that, he flew to the moon and made a Tulpa. He was also thinking about dogs chasing their tails.\n",
      "  Memory (call_ZplG0lepm3LUL7EulsxYo5o6)\n",
      " Call ID: call_ZplG0lepm3LUL7EulsxYo5o6\n",
      "  Args:\n",
      "    content: Angelo flew to the moon and made a Tulpa. He was also thinking about dogs chasing their tails.\n"
     ]
    }
   ],
   "source": [
    "result = trustcall_extractor.invoke({\"messages\": updated_conversation,\n",
    "                                     \"existing\": existing_memories})\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Angelo had a nice meal this morning and ate Shakshuka. After that, he flew to the moon and made a Tulpa. He was also thinking about dogs chasing their tails.'\n",
      "content='Angelo flew to the moon and made a Tulpa. He was also thinking about dogs chasing their tails.'\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_mF1o26UtKwTtgKAFra7PAqQt', 'json_doc_id': '0'}\n",
      "{'id': 'call_ZplG0lepm3LUL7EulsxYo5o6'}\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with collection schema updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. FOr example: User expressed interest in learning about the French.\")\n",
    "\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. You are designed to be a companion to a user.\n",
    "You have a long term memory which keeps track of information you learn about the user over time.\n",
    "Current Memory (may include updated memories from this conversation):\n",
    "{memory}\"\"\"\n",
    "\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction.\n",
    "Use the provided tools to retain any necessary memories about the user.\n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config:RunnableConfig, store:BaseStore):\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "\n",
    "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
    "\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config:RunnableConfig, store:BaseStore):\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    tool_name = \"Memory\"\n",
    "    existing_memories = ([(existing_items.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items else None)\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]))\n",
    "\n",
    "    result = trustcall_extractor.invoke({\"messages\": updated_messages, \"existing\": existing_memories})\n",
    "\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),)\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "across_thread_memory = InMemoryStore()\n",
    "within_thread_memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Angelo.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Angelo! It's great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Angelo.\")]\n",
    "\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to whip and naenae\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's awesome! \"Watch Me (Whip/Nae Nae)\" is such a fun song to dance to. Do you enjoy dancing to other songs as well?\n"
     ]
    }
   ],
   "source": [
    "input_messages = [HumanMessage(content=\"I like to whip and naenae\")]\n",
    "\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': {'content': 'User likes to whip and naenae, indicating an interest in dancing.'}, 'key': '0ddafe23-aa26-439f-9054-b09db43481c6', 'namespace': ['memories', '1'], 'created_at': '2025-01-01T23:16:21.587989+00:00', 'updated_at': '2025-01-01T23:16:21.587989+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "user_id = \"1\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also haven't slept for two days!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds really tough. Lack of sleep can affect how you feel and function. Is there something specific keeping you up, or do you often have trouble sleeping?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI also haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt slept for two days!\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/langgraph/pregel/__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1656\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/langgraph/utils/runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.13.0/lib/python3.13/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[24], line 43\u001b[0m, in \u001b[0;36mwrite_memory\u001b[0;34m(state, config, store)\u001b[0m\n\u001b[1;32m     40\u001b[0m existing_items \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39msearch(namespace)\n\u001b[1;32m     42\u001b[0m tool_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 43\u001b[0m existing_memories \u001b[38;5;241m=\u001b[39m ([(\u001b[43mexisting_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m, tool_name, existing_item\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m     44\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m existing_item \u001b[38;5;129;01min\u001b[39;00m existing_items]\n\u001b[1;32m     45\u001b[0m                       \u001b[38;5;28;01mif\u001b[39;00m existing_items \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m updated_messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(merge_message_runs(messages\u001b[38;5;241m=\u001b[39m[SystemMessage(content\u001b[38;5;241m=\u001b[39mTRUSTCALL_INSTRUCTION)] \u001b[38;5;241m+\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     48\u001b[0m result \u001b[38;5;241m=\u001b[39m trustcall_extractor\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: updated_messages, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting\u001b[39m\u001b[38;5;124m\"\u001b[39m: existing_memories})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'key'",
      "\u001b[0mDuring task with name 'write_memory' and id 'affb90ef-5235-75a6-ee63-51d35e9f4c82'"
     ]
    }
   ],
   "source": [
    "input_messages = [HumanMessage(content=\"I also haven't slept for two days!\")]\n",
    "\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
